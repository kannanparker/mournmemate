{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeRzFVi2Lljr",
        "outputId": "08488ded-0d57-48b4-fb23-e223bc150784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57KgGn9vL6XM",
        "outputId": "cddc69b1-f292-4782-a8b9-7c175cf7db93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.38.0 tenacity-8.5.0 watchdog-4.0.2\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "sKTbUdIyMDaO",
        "outputId": "15cbcfa6-419a-4ecd-9b66-7e95b8c49e2b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-71bd5d86293e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerativeai\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "2pDOvdsZMQfh",
        "outputId": "614be0ad-2657-444f-daf2-fad3b0f2f508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elara, a girl with braids as thick as rope and eyes the color of storm clouds, had always been curious. She was the kind of child who would dissect a dandelion to see what made it wish, who would stare into the sky for hours trying to count the clouds. But Elara had a secret. One that she tucked away in her heart, like a precious pebble: her grandmother's magic backpack.\n",
            "\n",
            "The backpack, a tapestry of faded greens and blues, was more than just a bag. It was a portal to other worlds, a treasure chest of forgotten stories.  Elara had discovered it tucked away in her grandmother's attic, along with a dusty map. It whispered of hidden waterfalls, talking trees, and cities made of clouds. \n",
            "\n",
            "Elara, ever the adventurer, couldn't resist. One starry night, she slipped the backpack on, the map clutched in her hand, and whispered the magic words: \"Show me wonder.\" The backpack hummed, and a swirling vortex of colors opened, sucking her in like a leaf in a hurricane. \n",
            "\n",
            "She landed with a soft thud on a field of shimmering grass. The air was thick with the scent of wild honey and blooming flowers. A magnificent, silver-winged bird landed beside her, its eyes like polished obsidian. It chirped, a sound that echoed with ancient wisdom, and then, with a gentle nudge, directed Elara towards a nearby clearing. \n",
            "\n",
            "There, bathed in the warm glow of a double moon, was a magnificent city. It was made of glass and moonlight, its buildings reaching for the stars.  Elara walked through its streets, marveling at the crystal bridges, the fountains that flowed with liquid starlight, and the people who spoke in songs. They were kind and welcoming, their laughter echoing through the city like wind chimes.\n",
            "\n",
            "Days turned into weeks, Elara learning their language, their stories, their ways. She learned about the magic of the stars, the secrets whispered by the wind, and the art of crafting light. She learned about their sadness too - the threat of a shadow that threatened to swallow their city.\n",
            "\n",
            "One day, a deep rumble shook the city. The shadow was here.  Fear rippled through the city like a tremor. But Elara, with her heart filled with the stories and lessons she had learned, knew what to do. \n",
            "\n",
            "Using the magic she'd learned, she crafted a beacon of light, powerful and bright. She climbed to the highest point of the city, the beacon in her hand, and pointed it towards the shadow. It pulsed with light, drawing the shadow towards it. \n",
            "\n",
            "The shadow, dark and hungry, devoured the light, its hunger only growing. But Elara, fueled by courage and love, continued to shine.  Finally, the shadow, bloated and sluggish, exploded in a shower of sparks, releasing the city from its grip. \n",
            "\n",
            "Elara, a small figure against the vast sky, had saved the city. She had become a hero, their savior.  But as the city celebrated, she knew it was time to go home. She slipped the backpack on, the map tucked inside, and whispered the magic words: \"Take me back.\"\n",
            "\n",
            "The backpack hummed, the world around her swirling back into existence. She landed back in her grandmother's attic, the map and the backpack clutched tightly in her hands. \n",
            "\n",
            "Elara, the girl with braids as thick as rope and eyes the color of storm clouds, had a new story to tell. A story of adventure, of kindness, and of the magic that lay within a backpack. A story that would forever stay with her, a reminder that even the smallest spark can light the way to wonder. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "genai.configure(api_key=\"AIzaSyBcyZutL_U1rTXQiNqr0ewYLdVH0Q-Lles\")\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "response = model.generate_content(\"Write a story about a magic backpack.\")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwRk3gvpN3T4",
        "outputId": "b30466de-5921-49af-d9a1-d333cd00987e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHeIGh9KOzdH",
        "outputId": "f6b0990b-88c6-446e-84f7-9bdef8a2da7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-21.6-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting httpx~=0.27 (from python-telegram-bot)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx~=0.27->python-telegram-bot)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx~=0.27->python-telegram-bot)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.2.2)\n",
            "Downloading python_telegram_bot-21.6-py3-none-any.whl (652 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m652.1/652.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, python-telegram-bot\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 python-telegram-bot-21.6\n"
          ]
        }
      ],
      "source": [
        "pip install python-telegram-bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sBJ5wZ-Ra4o"
      },
      "outputs": [],
      "source": [
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ae2xxQImRpGm",
        "outputId": "f1490871-71df-4cfe-f646-044d47f64561"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'genai' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-96f5a7b11bc7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Configure Gemini AI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGENAI_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Function to generate responses from Gemini AI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'genai' is not defined"
          ]
        }
      ],
      "source": [
        "GENAI_API_KEY = \"AIzaSyBcyZutL_U1rTXQiNqr0ewYLdVH0Q-Lles\"\n",
        "TELEGRAM_BOT_TOKEN = \"6842471021:AAE9RovwNxuo-W0sA6rX1BfTIFH9ONgSHBw\"\n",
        "\n",
        "\n",
        "# Configure Gemini AI\n",
        "genai.configure(api_key=GENAI_API_KEY)\n",
        "\n",
        "# Function to generate responses from Gemini AI\n",
        "def generate_text(prompt):\n",
        "    try:\n",
        "        response = genai.generate(prompt=prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Start command handler\n",
        "async def start(update: Update, context):\n",
        "    await update.message.reply_text(\"Hello! I'm your Gemini AI-powered bot. How can I assist you?\")\n",
        "\n",
        "# Handle user messages\n",
        "async def handle_message(update: Update, context):\n",
        "    user_message = update.message.text\n",
        "    ai_response = generate_text(user_message)\n",
        "    await update.message.reply_text(ai_response)\n",
        "\n",
        "# Main function to run the bot\n",
        "if __name__ == \"__main__\":\n",
        "    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()\n",
        "\n",
        "    # Commands and message handlers\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
        "\n",
        "    print(\"Bot is running...\")\n",
        "    app.run_polling()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MgASQ7zTLu0",
        "outputId": "b0eb0fa0-5108-4dec-be4a-64723b0824d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_cGHEMLTUKj"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGrhG6pRTWsc",
        "outputId": "c60765ea-6975-4154-fa7b-7081ae0f8756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot is running...\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Apply nest_asyncio to avoid runtime errors\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configuration\n",
        "GENAI_API_KEY = \"AIzaSyBcyZutL_U1rTXQiNqr0ewYLdVH0Q-Lles\"\n",
        "TELEGRAM_BOT_TOKEN = \"6842471021:AAE9RovwNxuo-W0sA6rX1BfTIFH9ONgSHBw\"\n",
        "\n",
        "# Define the chat_id of the person who will receive alerts\n",
        "ALERT_RECIPIENT_CHAT_ID = 1544276677  # Replace with the actual recipient's chat_id\n",
        "\n",
        "# Configure Gemini AI\n",
        "genai.configure(api_key=GENAI_API_KEY)\n",
        "\n",
        "# Dictionary to store user details based on chat_id\n",
        "user_data = {}\n",
        "\n",
        "# Function to generate responses from Gemini AI\n",
        "def generate_text(prompt, user_name):\n",
        "    try:\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        response = model.generate_content(f\"You are MournMeMate, an Indian medical chatbot. Respond to the user {user_name}:\\n\\n{prompt}\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Function to check for sensitive keywords\n",
        "def contains_sensitive_words(message):\n",
        "    sensitive_keywords = [\"suicide\", \"death\"]\n",
        "    return any(keyword in message.lower() for keyword in sensitive_keywords)\n",
        "\n",
        "# Start command handler (asks for name if new user)\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    chat_id = update.message.chat_id\n",
        "    if chat_id not in user_data:\n",
        "        user_data[chat_id] = {'state': 'ASK_NAME'}\n",
        "        await update.message.reply_text(\"Hello! Welcome to MournMeMate. What's your name?\")\n",
        "    else:\n",
        "        await update.message.reply_text(f\"Welcome back, {user_data[chat_id]['name']}! How can I assist you today?\")\n",
        "\n",
        "# Handle user input\n",
        "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    chat_id = update.message.chat_id\n",
        "    user_message = update.message.text\n",
        "\n",
        "    # Check the state of the conversation (asking name, age, or regular messages)\n",
        "    if user_data.get(chat_id, {}).get('state') == 'ASK_NAME':\n",
        "        # Store the user's name and ask for their age\n",
        "        user_data[chat_id]['name'] = user_message\n",
        "        user_data[chat_id]['state'] = 'ASK_AGE'\n",
        "        await update.message.reply_text(f\"Nice to meet you, {user_message}! How old are you?\")\n",
        "\n",
        "    elif user_data.get(chat_id, {}).get('state') == 'ASK_AGE':\n",
        "        # Store the user's age and proceed to normal conversation\n",
        "        user_data[chat_id]['age'] = user_message\n",
        "        user_data[chat_id]['state'] = 'READY'\n",
        "        await update.message.reply_text(f\"Thank you! You're {user_message} years old. How can I assist you today?\")\n",
        "\n",
        "    elif user_data.get(chat_id, {}).get('state') == 'READY':\n",
        "        # Normal conversation - Check for sensitive words\n",
        "        user_name = user_data[chat_id]['name']\n",
        "\n",
        "        if contains_sensitive_words(user_message):\n",
        "            # Send an alert to the specified user with the user's name and message\n",
        "            alert_message = f\"Alert! {user_name} mentioned sensitive words in their message: '{user_message}'\"\n",
        "            await context.bot.send_message(chat_id=ALERT_RECIPIENT_CHAT_ID, text=alert_message)\n",
        "\n",
        "        # Generate a response using Gemini AI\n",
        "        ai_response = generate_text(user_message, user_name)\n",
        "        await update.message.reply_text(ai_response)\n",
        "    else:\n",
        "        await update.message.reply_text(\"Please start by telling me your name using /start.\")\n",
        "\n",
        "# Main function to run the bot\n",
        "if __name__ == \"__main__\":\n",
        "    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()\n",
        "\n",
        "    # Commands and message handlers\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))  # Handles all user input\n",
        "\n",
        "    print(\"Bot is running...\")\n",
        "    app.run_polling()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}